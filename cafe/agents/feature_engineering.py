from pathlib import Path
from typing import Any, Dict

from cafe.core.semantic_model import SemanticModelManager
from cafe.core.snowflake_client import SnowflakeClient
from .base_agent import BaseAgent
from ..utils.config import load_config


class FeatureEngineeringAgent(BaseAgent):
    """Agent that generates feature engineering SQL queries using Cortex Analyst."""

    def __init__(self, snowflake_client: SnowflakeClient, semantic_model_manager: SemanticModelManager):
        super().__init__()
        self.snowflake_client = snowflake_client
        self.semantic_model_manager = semantic_model_manager
        self.host = load_config()["snowflake"]["host"]

    def run(self, prompt: str, semantic_model_path: str | Path) -> str:
        """Generate a feature engineering SQL query."""
        semantic_model = self.semantic_model_manager.load_yaml(semantic_model_path)
        response = self.ask_for_sql(prompt, semantic_model)
        for item in response["message"]["content"]:
            if item["type"] == "sql":
                self.logger.info(f"Generated SQL: {item['statement']}")
                return item["statement"]
        raise ValueError("No SQL generated by Cortex Analyst")

    def make_bussiness_quesiton(self, semantic_model_path: str | Path) -> str:
        """Generate a business question using the Snowflake LLM based on the semantic model."""
        semantic_model_content = self.semantic_model_manager.load_yaml(semantic_model_path)

        prompt = f"""
You are a helpful assistant whose goal is to generate one insightful question about the data described in the provided semantic model. This question should be relevant for creating new features that could improve the performance of a forecasting model (like XGBoost) for business metrics. The question can also be framed from a business analytics perspective, aiming to uncover meaningful trends or patterns.

Here is the content of the semantic model file:
```yaml
{semantic_model_content}
```
"""
        response = self.call_llm(prompt)
        self.logger.info(f"Generated business question: {response}")
        answer = response["choices"][0]["message"]["content"]
        self.logger.info(f"Generated business question: {answer}")
        return answer

    def ask_for_sql(self, prompt: str, semantic_model: str) -> Dict[str, Any]:
        """Send a message to Cortex Analyst API."""
        request_body = {
            "messages": [{"role": "user", "content": [{"type": "text", "text": prompt}]}],
            "semantic_model": semantic_model,
        }

        return self.snowflake_client.call_cortex_analyst(request_body)

    def call_cortex_tool(self, prompt: str) -> dict:
        """Call the Cortex tool API with a prompt and return the response."""
        data = {
            "model": "claude-3-5-sonnet",
            "messages": [{"role": "user", "content": prompt}],
            "tools": [
                {
                    "tool_spec": {
                        "type": "generic",
                        "name": "get_weather",
                        "input_schema": {
                            "type": "object",
                            "properties": {
                                "location": {
                                    "type": "string",
                                    "description": "The city and state, e.g. San Francisco, CA"
                                }
                            },
                            "required": ["location"]
                        }
                    }
                }
            ],
            "max_tokens": 4096,
            "top_p": 1,
            "stream": False
        }

        return self.snowflake_client.call_cortex_llm(data)

    def call_llm(self, prompt: str) -> dict:
        """Call the Cortex tool API with a prompt and return the response."""
        data = {
            "model": "claude-3-5-sonnet",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 4096,
            "top_p": 1,
            "stream": False
        }

        return self.snowflake_client.call_cortex_llm(data)
